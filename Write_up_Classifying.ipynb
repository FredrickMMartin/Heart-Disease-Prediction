{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea065bc9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1edb08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T11:21:42.625794Z",
     "start_time": "2021-11-20T11:21:42.613466Z"
    },
    "hidden": true
   },
   "source": [
    "To create an algorithm to predict the presence of heart disease based on the values of 13 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa3931",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24fed9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:58:25.170403Z",
     "start_time": "2022-05-16T15:58:17.697856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "# pipeline functions\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# useful additional functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df539294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:58:26.071265Z",
     "start_time": "2022-05-16T15:58:25.173398Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec579bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:58:58.254871Z",
     "start_time": "2022-05-16T15:58:58.221457Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read pickled df \n",
    "df = pd.read_pickle('extended_heart_disease.pkl')\n",
    "\n",
    "\n",
    "# split data\n",
    "features = list(df.columns)\n",
    "features.remove('target')\n",
    "\n",
    "#split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features]\n",
    "                                                    , df['target']\n",
    "                                                    , test_size = 0.2\n",
    "                                                    , random_state = 42\n",
    "                                                    , stratify = df['target'])\n",
    "\n",
    "# read valuable lists\n",
    "with open('useful_lists.pkl', 'rb') as f:\n",
    "    valuable_lists = pkl.load(f)\n",
    "\n",
    "num_features = valuable_lists['num_features']\n",
    "cat_features = valuable_lists['cat_features']\n",
    "products = valuable_lists['products']\n",
    "divisions = valuable_lists['divisions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee9fef",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Establishing baseline performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b052f6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before we begin trying to develop an optimised classifier we should establish a base line to compare improvement against.\n",
    "We will be using f1-scoring to control for any effect of the higher proportion of negatives in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d75268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:59:03.257889Z",
     "start_time": "2022-05-16T15:58:58.257909Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222015</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>0.024064</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.01</td>\n",
       "      <td>42</td>\n",
       "      <td>{'min_samples_leaf': 0.01, 'random_state': 42}</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.842495</td>\n",
       "      <td>0.036234</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.223750</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.05</td>\n",
       "      <td>42</td>\n",
       "      <td>{'min_samples_leaf': 0.05, 'random_state': 42}</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.856038</td>\n",
       "      <td>0.028780</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.204341</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'min_samples_leaf': 0.1, 'random_state': 42}</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.845772</td>\n",
       "      <td>0.028704</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197707</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'min_samples_leaf': 0.2, 'random_state': 42}</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857061</td>\n",
       "      <td>0.024596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.222015      0.013017         0.024064        0.003835   \n",
       "1       0.223750      0.017291         0.024223        0.001864   \n",
       "2       0.204341      0.005271         0.022147        0.001015   \n",
       "3       0.197707      0.012857         0.021875        0.001136   \n",
       "\n",
       "  param_min_samples_leaf param_random_state  \\\n",
       "0                   0.01                 42   \n",
       "1                   0.05                 42   \n",
       "2                    0.1                 42   \n",
       "3                    0.2                 42   \n",
       "\n",
       "                                           params  split0_test_score  \\\n",
       "0  {'min_samples_leaf': 0.01, 'random_state': 42}           0.785714   \n",
       "1  {'min_samples_leaf': 0.05, 'random_state': 42}           0.813559   \n",
       "2   {'min_samples_leaf': 0.1, 'random_state': 42}           0.793103   \n",
       "3   {'min_samples_leaf': 0.2, 'random_state': 42}           0.827586   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.852459           0.830189           0.897959           0.846154   \n",
       "1           0.866667           0.846154           0.901961           0.851852   \n",
       "2           0.852459           0.846154           0.880000           0.857143   \n",
       "3           0.852459           0.846154           0.901961           0.857143   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.842495        0.036234                4  \n",
       "1         0.856038        0.028780                2  \n",
       "2         0.845772        0.028704                3  \n",
       "3         0.857061        0.024596                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'min_samples_leaf' : (0.01, 0.05, 0.1, 0.2), 'random_state' : [42]}\n",
    "\n",
    "# the baseline should be taken on the original features, before any additions were made\n",
    "original_features = ['thal'] + num_features + cat_features \n",
    "\n",
    "gscv = GridSearchCV(RandomForestClassifier(), parameters, cv=5, scoring = 'f1')\n",
    "gscv.fit(X_train[original_features], y_train)\n",
    "\n",
    "pd.DataFrame(gscv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5e286",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ok so based on a very simple Grid Search we can take a baseline of 0.857"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8f287",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pipeline design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e5e616",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Qualities that we require from the pipeline:\n",
    "- categorical features must be encoded to ensure that they are not treated numerically\n",
    "- numerical features, where possible, should be scaled\n",
    "- we should have flexibility in using different algorithms/feature subsets within the same grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5058960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:59:03.273035Z",
     "start_time": "2022-05-16T15:59:03.262299Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for transforming numerical features\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# for transforming categorical features\n",
    "# We have encoded categorical features so that, e.g. 1 and 2 are not considered more similar than 1 and 3 when all 3 values just encode different categories.\n",
    "categorical_transformer = OneHotEncoder(handle_unknown = 'ignore')\n",
    "\n",
    "# create ColumnTransformer to transform categorical and numerical features separately\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers =[\n",
    "        ('num', numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', categorical_transformer, selector(dtype_include=\"category\"))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b2bf07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:59:03.288646Z",
     "start_time": "2022-05-16T15:59:03.277502Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# this enables us to try different classifiers within the same grid search\n",
    "# taken from the user cgnorthcutt on stackoverflow\n",
    "class ClfSwitcher(BaseEstimator):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        estimator = RandomForestClassifier(),\n",
    "        ):\n",
    "        \"\"\"\n",
    "        A Custom BaseEstimator that can switch between classifiers.\n",
    "        :param estimator: sklearn object - The classifier\n",
    "        \"\"\" \n",
    "\n",
    "        self.estimator = estimator\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d4ae44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:59:03.303842Z",
     "start_time": "2022-05-16T15:59:03.292695Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# this class is designed to enable switching between the features that are used within the same grid search\n",
    "class FeatureSelector(BaseEstimator):\n",
    "\n",
    "    def __init__(self, chosen_features = None):\n",
    "        self.chosen_features = chosen_features\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X[self.chosen_features]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd27cb",
   "metadata": {},
   "source": [
    "## Exploring performance on feature subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec18978",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f39548a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:59:03.319062Z",
     "start_time": "2022-05-16T15:59:03.307139Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create different subsets of features to test performance on\n",
    "original_features =  ['thal'] + num_features + cat_features\n",
    "\n",
    "feature_subsets = (\n",
    "    original_features\n",
    "    , original_features + divisions\n",
    "    , original_features + products\n",
    "    , original_features + divisions + products\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f404ff",
   "metadata": {},
   "source": [
    "### Initial gridsearch for classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f226556",
   "metadata": {},
   "source": [
    "Let's begin by just taking a look at 3 simple classifiers and see how they perform when given a small scope of variation in their hyper-parameters.\n",
    "We will use grid-search to explore different instances of each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8bca425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:59:03.334214Z",
     "start_time": "2022-05-16T15:59:03.321470Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector', FeatureSelector())\n",
    "    , ('preprocessor', preprocessor)\n",
    "    , ('clf', ClfSwitcher())\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "        'clf__estimator' : [RandomForestClassifier(random_state = 42)]\n",
    "        , 'clf__estimator__class_weight' : ('balanced', None)\n",
    "        , 'selector__chosen_features' : feature_subsets\n",
    "        , 'clf__estimator__min_samples_leaf' : (0.02, 0.05, 0.1, 0.2, 0.5)\n",
    "    }\n",
    "    \n",
    "    ,{\n",
    "       'clf__estimator' : [LogisticRegression(random_state = 42)]\n",
    "        , 'clf__estimator__class_weight' : ('balanced', None)\n",
    "        , 'selector__chosen_features' : feature_subsets\n",
    "        , 'clf__estimator__C' : (1.0, 0.3, 0.1, 0.03, 0.01)\n",
    "    }\n",
    "    \n",
    "    ,{\n",
    "       'clf__estimator' : [SVC(random_state = 42)]\n",
    "        , 'clf__estimator__class_weight' : ('balanced', None)\n",
    "        , 'selector__chosen_features' : feature_subsets\n",
    "        , 'clf__estimator__C' : (1.0, 0.3, 0.1, 0.03, 0.01)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb05c69d",
   "metadata": {},
   "source": [
    "Here we are varying a number of different parameters.\n",
    "Firstly, we are testing with different algorithms.  \n",
    "Secondly, we are testing with balancing the weights in our cost function, in cases where class_weight = 'balanced', the cost function will take into account the fact that there are slightly more cases where heart disease is present than cases where it is not.\n",
    "Finally, we are testing different subsets of the features that we have brought through from the expanded feature set. This will allow us to measure the impact of including features and help us establish whether to include them within our algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a4e9e1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:00:20.956916Z",
     "start_time": "2022-05-16T15:59:03.339910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('selector', FeatureSelector()),\n",
       "                                       ('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x0000026461C960A0>),\n",
       "                                                                        ('cat',\n",
       "                                                                         OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x0000...\n",
       "                                                         'trestbps', 'chol',\n",
       "                                                         'thalach', 'oldpeak',\n",
       "                                                         'sex', 'cp', 'fbs',\n",
       "                                                         'restecg', 'exang',\n",
       "                                                         'slope', 'ca',\n",
       "                                                         'age / trestbps',\n",
       "                                                         'age / chol',\n",
       "                                                         'age / thalach',\n",
       "                                                         'trestbps / age',\n",
       "                                                         'trestbps / chol',\n",
       "                                                         'trestbps / thalach',\n",
       "                                                         'chol / age',\n",
       "                                                         'chol / trestbps',\n",
       "                                                         'chol / thalach',\n",
       "                                                         'thalach / age',\n",
       "                                                         'thalach / trestbps',\n",
       "                                                         'thalach / chol',\n",
       "                                                         'oldpeak / age',\n",
       "                                                         'oldpeak / trestbps',\n",
       "                                                         'oldpeak / chol',\n",
       "                                                         'oldpeak / thalach',\n",
       "                                                         'age * age', ...])}],\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv = GridSearchCV(pipeline, parameters, cv = 5, scoring = 'f1')\n",
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584adac6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exploring results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2d1d3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Presenting results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c934f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In order to perform analysis on the results of the grid search it is easier for us to format the results as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cefe7af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:00:20.972518Z",
     "start_time": "2022-05-16T16:00:20.961206Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs1_results = pd.DataFrame(gscv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "883af146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:01:32.305729Z",
     "start_time": "2022-05-16T16:01:32.288782Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def renaming_features(x):\n",
    "    '''\n",
    "    The purpose of this function is to receive one of 4 specified features sets (as a list) and to return a string, naming that feature set\n",
    "    '''\n",
    "    if x == original_features:\n",
    "        return 'original features'\n",
    "    elif x == original_features + divisions:\n",
    "        return 'original features + divisions'\n",
    "    elif x == original_features + products:\n",
    "        return 'original features + products'\n",
    "    elif x == original_features + divisions + products:\n",
    "        return 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb97b150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:01:39.107737Z",
     "start_time": "2022-05-16T16:01:39.094574Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add a column for the feature subset name\n",
    "gs1_results['features'] = gs1_results['param_selector__chosen_features'].apply(lambda x: renaming_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87ad4c62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:01:39.123015Z",
     "start_time": "2022-05-16T16:01:39.111395Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# separate out instances of different algorithms\n",
    "rf1_results = gs1_results.loc[0 : 39].copy()\n",
    "logres1_results = gs1_results.loc[40 : 79].copy()\n",
    "svm1_results = gs1_results.loc[80 : 119].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa32c6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Top performers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9bd2d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First of all let us look at the top performing of all the classifier instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b179dd5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:01:39.169718Z",
     "start_time": "2022-05-16T16:01:39.126365Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__estimator</th>\n",
       "      <th>features</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>LogisticRegression(C=0.3, random_state=42)</td>\n",
       "      <td>original features + divisions</td>\n",
       "      <td>0.862649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>LogisticRegression(C=0.3, random_state=42)</td>\n",
       "      <td>original features + divisions</td>\n",
       "      <td>0.862327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>LogisticRegression(C=0.3, random_state=42)</td>\n",
       "      <td>original features</td>\n",
       "      <td>0.861140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>LogisticRegression(C=0.3, random_state=42)</td>\n",
       "      <td>original features + products</td>\n",
       "      <td>0.861140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>LogisticRegression(C=0.3, random_state=42)</td>\n",
       "      <td>original features + divisions</td>\n",
       "      <td>0.859593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LogisticRegression(C=0.3, random_state=42)</td>\n",
       "      <td>original features</td>\n",
       "      <td>0.858844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>original features</td>\n",
       "      <td>0.858572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>LogisticRegression(C=0.3, random_state=42)</td>\n",
       "      <td>all</td>\n",
       "      <td>0.858205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LogisticRegression(C=0.3, random_state=42)</td>\n",
       "      <td>original features</td>\n",
       "      <td>0.857455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>original features</td>\n",
       "      <td>0.857179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          param_clf__estimator                       features  \\\n",
       "53  LogisticRegression(C=0.3, random_state=42)  original features + divisions   \n",
       "49  LogisticRegression(C=0.3, random_state=42)  original features + divisions   \n",
       "52  LogisticRegression(C=0.3, random_state=42)              original features   \n",
       "54  LogisticRegression(C=0.3, random_state=42)   original features + products   \n",
       "61  LogisticRegression(C=0.3, random_state=42)  original features + divisions   \n",
       "40  LogisticRegression(C=0.3, random_state=42)              original features   \n",
       "28     RandomForestClassifier(random_state=42)              original features   \n",
       "55  LogisticRegression(C=0.3, random_state=42)                            all   \n",
       "48  LogisticRegression(C=0.3, random_state=42)              original features   \n",
       "24     RandomForestClassifier(random_state=42)              original features   \n",
       "\n",
       "    mean_test_score  \n",
       "53         0.862649  \n",
       "49         0.862327  \n",
       "52         0.861140  \n",
       "54         0.861140  \n",
       "61         0.859593  \n",
       "40         0.858844  \n",
       "28         0.858572  \n",
       "55         0.858205  \n",
       "48         0.857455  \n",
       "24         0.857179  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1_results.sort_values('mean_test_score', inplace = True, ascending = False)\n",
    "gs1_results.head(10)[['param_clf__estimator', 'features', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b43d9c7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So whilst the top 10 is predominantly composed of LogisticRegression algorithms, the top 2 are both RandomForest.\n",
    "Performance is not noteworthily better than baseline performance, particularly given the number of instances that we are testing here.\n",
    "120 instances were tested and the performance of the 10th best is only just above that of the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13acd7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaa270cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:01:39.216923Z",
     "start_time": "2022-05-16T16:01:39.171530Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>param_clf__estimator__class_weight</th>\n",
       "      <th>param_clf__estimator__min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>original features</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.858572</td>\n",
       "      <td>0.057828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>original features</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.857179</td>\n",
       "      <td>0.030151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>original features</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.855353</td>\n",
       "      <td>0.051857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>original features</td>\n",
       "      <td>None</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.846730</td>\n",
       "      <td>0.023988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>original features</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.844993</td>\n",
       "      <td>0.053216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>original features</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.834522</td>\n",
       "      <td>0.046426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>original features + products</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.826956</td>\n",
       "      <td>0.031229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original features</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.826784</td>\n",
       "      <td>0.040586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>original features + divisions</td>\n",
       "      <td>None</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.825236</td>\n",
       "      <td>0.049661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>original features + products</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.823015</td>\n",
       "      <td>0.033650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         features param_clf__estimator__class_weight  \\\n",
       "28              original features                               None   \n",
       "24              original features                               None   \n",
       "32              original features                               None   \n",
       "20              original features                               None   \n",
       "12              original features                           balanced   \n",
       "8               original features                           balanced   \n",
       "30   original features + products                               None   \n",
       "4               original features                           balanced   \n",
       "21  original features + divisions                               None   \n",
       "26   original features + products                               None   \n",
       "\n",
       "   param_clf__estimator__min_samples_leaf  mean_test_score  std_test_score  \n",
       "28                                    0.1         0.858572        0.057828  \n",
       "24                                   0.05         0.857179        0.030151  \n",
       "32                                    0.2         0.855353        0.051857  \n",
       "20                                   0.02         0.846730        0.023988  \n",
       "12                                    0.2         0.844993        0.053216  \n",
       "8                                     0.1         0.834522        0.046426  \n",
       "30                                    0.1         0.826956        0.031229  \n",
       "4                                    0.05         0.826784        0.040586  \n",
       "21                                   0.02         0.825236        0.049661  \n",
       "26                                   0.05         0.823015        0.033650  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1_results.sort_values('mean_test_score', inplace = True, ascending = False)\n",
    "rf_columns = ['features', 'param_clf__estimator__class_weight', 'param_clf__estimator__min_samples_leaf', 'mean_test_score', 'std_test_score']\n",
    "rf1_results.head(10)[rf_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c4c48",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Random forest is consistently performing best when only given the original features to train on. All 8 cases where the algorithm is just trained on those features are returned in the top 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c85ff9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cd9d3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:01:39.247979Z",
     "start_time": "2022-05-16T16:01:39.219909Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>param_clf__estimator__class_weight</th>\n",
       "      <th>param_clf__estimator__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>original features + divisions</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.862649</td>\n",
       "      <td>0.041714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>original features + divisions</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.862327</td>\n",
       "      <td>0.050393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>original features</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.861140</td>\n",
       "      <td>0.044026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>original features + products</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.861140</td>\n",
       "      <td>0.044026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>original features + divisions</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.859593</td>\n",
       "      <td>0.043718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>original features</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.858844</td>\n",
       "      <td>0.046527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.858205</td>\n",
       "      <td>0.048744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>original features</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.857455</td>\n",
       "      <td>0.037908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>original features + divisions</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855676</td>\n",
       "      <td>0.049281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>original features + products</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.855018</td>\n",
       "      <td>0.035780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         features param_clf__estimator__class_weight  \\\n",
       "53  original features + divisions                               None   \n",
       "49  original features + divisions                           balanced   \n",
       "52              original features                               None   \n",
       "54   original features + products                               None   \n",
       "61  original features + divisions                               None   \n",
       "40              original features                           balanced   \n",
       "55                            all                               None   \n",
       "48              original features                           balanced   \n",
       "41  original features + divisions                           balanced   \n",
       "62   original features + products                               None   \n",
       "\n",
       "   param_clf__estimator__C  mean_test_score  std_test_score  \n",
       "53                     0.3         0.862649        0.041714  \n",
       "49                     0.3         0.862327        0.050393  \n",
       "52                     0.3         0.861140        0.044026  \n",
       "54                     0.3         0.861140        0.044026  \n",
       "61                     0.1         0.859593        0.043718  \n",
       "40                     1.0         0.858844        0.046527  \n",
       "55                     0.3         0.858205        0.048744  \n",
       "48                     0.3         0.857455        0.037908  \n",
       "41                     1.0         0.855676        0.049281  \n",
       "62                     0.1         0.855018        0.035780  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logres1_results.sort_values('mean_test_score', inplace = True, ascending = False)\n",
    "logres_columns = ['features', 'param_clf__estimator__class_weight', 'param_clf__estimator__C', 'mean_test_score', 'std_test_score']\n",
    "logres1_results.head(10)[logres_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17df5c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The range of performance within the top 10 logisitc regression options is a lot smaller than that seen with Random Forest.\n",
    "There is also a lot more variety in the features being used in each instance of the algorithm and no one set of features seems dominant.\n",
    "The most consistent feature is that 0.3 seems to be the optimal value of C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b921ee",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0629afa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:01:39.294532Z",
     "start_time": "2022-05-16T16:01:39.251125Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>param_clf__estimator__class_weight</th>\n",
       "      <th>param_clf__estimator__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>original features</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.840156</td>\n",
       "      <td>0.056151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>original features</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.828256</td>\n",
       "      <td>0.028627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>original features + products</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.824934</td>\n",
       "      <td>0.035799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>original features</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.822939</td>\n",
       "      <td>0.031733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>original features</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.822182</td>\n",
       "      <td>0.034039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>original features</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.814604</td>\n",
       "      <td>0.044908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>original features</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.811379</td>\n",
       "      <td>0.041196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>original features + products</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.803524</td>\n",
       "      <td>0.036047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.803038</td>\n",
       "      <td>0.048812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>all</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.801570</td>\n",
       "      <td>0.050821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         features param_clf__estimator__class_weight  \\\n",
       "84              original features                               None   \n",
       "80              original features                           balanced   \n",
       "86   original features + products                               None   \n",
       "92              original features                               None   \n",
       "88              original features                           balanced   \n",
       "96              original features                           balanced   \n",
       "100             original features                               None   \n",
       "82   original features + products                           balanced   \n",
       "87                            all                               None   \n",
       "83                            all                           balanced   \n",
       "\n",
       "    param_clf__estimator__C  mean_test_score  std_test_score  \n",
       "84                      1.0         0.840156        0.056151  \n",
       "80                      1.0         0.828256        0.028627  \n",
       "86                      1.0         0.824934        0.035799  \n",
       "92                      0.3         0.822939        0.031733  \n",
       "88                      0.3         0.822182        0.034039  \n",
       "96                      0.1         0.814604        0.044908  \n",
       "100                     0.1         0.811379        0.041196  \n",
       "82                      1.0         0.803524        0.036047  \n",
       "87                      1.0         0.803038        0.048812  \n",
       "83                      1.0         0.801570        0.050821  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm1_results.sort_values('mean_test_score', inplace = True, ascending = False)\n",
    "svm_columns = ['features', 'param_clf__estimator__class_weight', 'param_clf__estimator__C', 'mean_test_score', 'std_test_score']\n",
    "svm1_results.head(10)[svm_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9998e6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "SVM is performing far below the level of random forest and logistic regression.\n",
    "The algorithm is generally performing better when trained on just the original features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f693d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Overarching patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a471514",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Although a small number of instances of the classifiers have outperformed the baseline, the vast majority have not.\n",
    "In fact the highest performing instance in the gridsearch was one of the 3 instances considered in the baseline.\n",
    "This indicates that nothing we have done so far has achieved any improvement on the baseline.\n",
    "\n",
    "From here on I shall not be using balanced class_weight as in most side-by-side comparisons, balancing the class weights actually reduced performance (measured on f1-score).\n",
    "\n",
    "If I were performing a more extended analysis I would explore whether this reduction is due to the fact that test_score is evaluated as a simple accuracy percentage, therefore meaning that f1-score might be better when class_weight = 'balanced', however I will not go into this here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59088ba7",
   "metadata": {},
   "source": [
    "## Trying to improve performance of individual algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230d67a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Removing scaling and one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff1a43",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The majority of the instances of algorithms tested above performed worse than the baseline which included no scaling/feature encoding. We will explore here whether this processing of the features is actually harming our algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ee77b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d35861fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:01:58.980877Z",
     "start_time": "2022-05-16T16:01:39.297142Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>originals</th>\n",
       "      <th>originals + divisors</th>\n",
       "      <th>originals + products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.840616</td>\n",
       "      <td>0.813648</td>\n",
       "      <td>0.841341</td>\n",
       "      <td>0.808004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.856038</td>\n",
       "      <td>0.811671</td>\n",
       "      <td>0.831829</td>\n",
       "      <td>0.812376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.845772</td>\n",
       "      <td>0.802818</td>\n",
       "      <td>0.829333</td>\n",
       "      <td>0.811743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.857061</td>\n",
       "      <td>0.814149</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.796578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           all  originals  originals + divisors  originals + products\n",
       "0.02  0.840616   0.813648              0.841341              0.808004\n",
       "0.05  0.856038   0.811671              0.831829              0.812376\n",
       "0.1   0.845772   0.802818              0.829333              0.811743\n",
       "0.2   0.857061   0.814149              0.787879              0.796578"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector', FeatureSelector())\n",
    "    , ('rf', RandomForestClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "        'selector__chosen_features' : feature_subsets\n",
    "        , 'rf__min_samples_leaf' : (0.02,0.05, 0.1, 0.2)\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, cv = 5, scoring = 'f1')\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "rf_no_scaling_results = pd.DataFrame(data=gscv.cv_results_['mean_test_score'].reshape(4, 4), columns=[\"all\", \"originals\", \"originals + divisors\", \"originals + products\"], index=[\"0.02\", \"0.05\", \"0.1\", \"0.2\"])\n",
    "rf_no_scaling_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6b284",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ok so performance here is pretty similar to that that seen above.\n",
    "this makes sense given that random forests are unaffected by feature scaling, however there could be a difference made by the OneHotEncoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f0801",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14422c40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:02:04.545667Z",
     "start_time": "2022-05-16T16:01:58.985174Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredr\\anaconda3\\envs\\financial_project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>originals</th>\n",
       "      <th>originals + divisors</th>\n",
       "      <th>originals + products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.853731</td>\n",
       "      <td>0.863295</td>\n",
       "      <td>0.761192</td>\n",
       "      <td>0.761280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.861138</td>\n",
       "      <td>0.860518</td>\n",
       "      <td>0.764127</td>\n",
       "      <td>0.761055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.857350</td>\n",
       "      <td>0.857511</td>\n",
       "      <td>0.765636</td>\n",
       "      <td>0.764127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>0.834224</td>\n",
       "      <td>0.834224</td>\n",
       "      <td>0.764243</td>\n",
       "      <td>0.756639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.786869</td>\n",
       "      <td>0.797796</td>\n",
       "      <td>0.765636</td>\n",
       "      <td>0.762779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           all  originals  originals + divisors  originals + products\n",
       "1.0   0.853731   0.863295              0.761192              0.761280\n",
       "0.3   0.861138   0.860518              0.764127              0.761055\n",
       "0.1   0.857350   0.857511              0.765636              0.764127\n",
       "0.03  0.834224   0.834224              0.764243              0.756639\n",
       "0.01  0.786869   0.797796              0.765636              0.762779"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector', FeatureSelector())\n",
    "    , ('logres', LogisticRegression(random_state = 42))\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "        'selector__chosen_features' : feature_subsets\n",
    "        , 'logres__C' : (1.0, 0.3, 0.1, 0.03, 0.01)\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, cv = 5, scoring = 'f1')\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "logres_no_scaling_results = pd.DataFrame(data=gscv.cv_results_['mean_test_score'].reshape(5, 4), columns=[\"all\", \"originals\", \"originals + divisors\", \"originals + products\"], index=[\"1.0\", \"0.3\", \"0.1\", \"0.03\", \"0.01\"])\n",
    "logres_no_scaling_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f898c565",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As a result of no longer scaling the data we get cases where the algorithm fails to converge.\n",
    "Interestingly here, performance has dropped much more in the cases where we include the products. For cases where these are not included, the performance only changes minimally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a1dbc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7ef6257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:02:07.071966Z",
     "start_time": "2022-05-16T16:02:04.548659Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>originals</th>\n",
       "      <th>originals + divisors</th>\n",
       "      <th>originals + products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.705711</td>\n",
       "      <td>0.709652</td>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.705832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.708859</td>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.705832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.679702</td>\n",
       "      <td>0.704367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.670580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.697987</td>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.705832</td>\n",
       "      <td>0.705832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           all  originals  originals + divisors  originals + products\n",
       "1.0   0.705711   0.709652              0.705832              0.705832\n",
       "0.3   0.705832   0.708859              0.705832              0.705832\n",
       "0.1   0.705832   0.705832              0.679702              0.704367\n",
       "0.03  0.705832   0.705832              0.705832              0.670580\n",
       "0.01  0.697987   0.705832              0.705832              0.705832"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector', FeatureSelector())\n",
    "    , ('svm', SVC(random_state = 42))\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "        'selector__chosen_features' : feature_subsets\n",
    "        , 'svm__C' : (1.0, 0.3, 0.1, 0.03, 0.01)\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, cv = 5, scoring = 'f1')\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "svm_no_scaling_results = pd.DataFrame(data=gscv.cv_results_['mean_test_score'].reshape(5, 4), columns=[\"all\", \"originals\", \"originals + divisors\", \"originals + products\"], index=[\"1.0\", \"0.3\", \"0.1\", \"0.03\", \"0.01\"])\n",
    "svm_no_scaling_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049bdc3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Performance here has dropped off significantly.\n",
    "Although SVM performance was below that of the other algorithms in the initial testing it has dropped off significantly here.\n",
    "This seems reasonable given that, by not scaling the features, the importance of features will be somewhat correlated to the variance of the values of those features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387bbfcb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee2420",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It looks as though in the case of Random Forest, there is at most a minimal difference caused by the scaling and encoding, perhaps because of the encoding of categorical features making separation of values in these cases easier.\n",
    "As one would expect, the removing of scaling had a much more pronounced impact on the performance of the other two algorithms.\n",
    "\n",
    "Given these results, we will continue using encoding and feature scaling going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be4d787",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exploring different feature subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e9a6f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Feature Importances with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df2ee6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b976277d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:02:07.087355Z",
     "start_time": "2022-05-16T16:02:07.074816Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_importance_generator(features):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor)\n",
    "        , ('rf', RandomForestClassifier(min_samples_leaf = 0.02))\n",
    "    ])\n",
    "    \n",
    "    '''\n",
    "    This function will allow us to generate feature importances for our instances of random forests.\n",
    "    '''\n",
    "\n",
    "    clf = pipeline.fit(X_train[features], y_train)\n",
    "    \n",
    "    # generate list of post-processing feature names\n",
    "    num_scale_features =  preprocessor.transformers_[0][2]\n",
    "    cat_one_hot_features = preprocessor.transformers_[1][1].get_feature_names(cat_features)\n",
    "    feature_names = num_scale_features + list(cat_one_hot_features)\n",
    "    \n",
    "    #collate feature importances and order\n",
    "    feature_importances = list(zip(feature_names, list(clf.steps[-1][-1].feature_importances_)))\n",
    "\n",
    "    for feature, importance in sorted(feature_importances, key=lambda x: x[1], reverse = True):\n",
    "        if importance > 0.02:\n",
    "            print(feature, \":\", importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bef87432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:02:07.381973Z",
     "start_time": "2022-05-16T16:02:07.090004Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp_0 : 0.16850592746439225\n",
      "thal : 0.11758132407196134\n",
      "oldpeak : 0.11078863102188798\n",
      "ca_0 : 0.08067781556041208\n",
      "thalach : 0.07944634145752016\n",
      "exang_0 : 0.06638383656684561\n",
      "exang_1 : 0.057309784401724254\n",
      "slope_2 : 0.05418272648559401\n",
      "age : 0.045352903624305815\n",
      "chol : 0.03811753821134368\n",
      "trestbps : 0.03118497814389147\n",
      "slope_1 : 0.029647727129299094\n",
      "sex_1 : 0.02462467802404727\n",
      "cp_2 : 0.021961365226846916\n"
     ]
    }
   ],
   "source": [
    "feature_importance_generator(original_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1adcec",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The results here are not as easy to interpret as we might like them to be.\n",
    "The importance of the categorical features is separated between the different encoded versions of the features and by virtue of there being more features related to (e.g. cp) than there are for numerical features, they are more likely to be selected in the random set of features that can be used to at each node and therefore be attributed more importance.\n",
    "\n",
    "Having said that, this is a good position to start from when comparing later results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd5a65",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Generating an optimal feature set from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f4fc8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's trial performance when we only feed in the more powerful features and see if this helps in any way. Importantly we will see if performance is consistently improved by the addition of these features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e01cfb",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "042fb121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:24:59.099152Z",
     "start_time": "2022-05-17T08:24:59.072372Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_evaluater(start_features, all_features, classifier, X_train, y_train, no_improvement_limit = 1):\n",
    "    \"\"\"\n",
    "    Trains a classifier on X_train and y_train using an increasing subset of the features to identify the optimal features\n",
    "    to use from within the set.\n",
    "    Returns a df of the features added each time and the performance.\n",
    "    No_improvement_limit specifies the number of features that can be added in a row without performance improving.\n",
    "    \"\"\"\n",
    "    \n",
    "    # adjust all_features so that it now contains just the features that we want to test for inclusion\n",
    "    for feature in start_features:\n",
    "        all_features.remove(feature)\n",
    "        \n",
    "    # rename the list\n",
    "    non_included_features = all_features\n",
    "    \n",
    "    # create a new name for start_features that will be returned as the list of optimum features \n",
    "    current_features = start_features\n",
    "    \n",
    "    round_count = 1\n",
    "    \n",
    "    # create counter for number of features that have been added without improving performance\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    # set baseline for top score thus far, this variable will represent the top socre achieved thus far\n",
    "    top_score = 0.01\n",
    "    \n",
    "    # create list to keep track of scores\n",
    "    scores = []\n",
    "    \n",
    "    # create list to keep track of features added\n",
    "    features = []\n",
    "    \n",
    "    # create list to keep track of best_features\n",
    "    best_features = start_features.copy()\n",
    "\n",
    "    # loop for as long as we do not exceed the limit of added feature without improvement\n",
    "    while no_improvement_count < no_improvement_limit:\n",
    "        # create all the subsets to test\n",
    "        new_feature_subsets = tuple([current_features + [feature] for feature in all_features])\n",
    "\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "        ('selector', FeatureSelector())\n",
    "        , ('preprocessor', preprocessor)\n",
    "        , ('clf', classifier)\n",
    "        ])\n",
    "\n",
    "        parameters = {\n",
    "                'selector__chosen_features' : new_feature_subsets\n",
    "            }\n",
    "\n",
    "        gscv_99 = GridSearchCV(pipeline, parameters, cv = 5, scoring = 'f1')\n",
    "        gscv_99.fit(X_train, y_train)\n",
    "\n",
    "        gs99_results = pd.DataFrame(gscv_99.cv_results_)\n",
    "        \n",
    "        new_scores = gs99_results['mean_test_score']\n",
    "        new_feature_index = new_scores.idxmax()\n",
    "        new_features = gs99_results['param_selector__chosen_features'][new_feature_index]\n",
    "        score = new_scores[new_feature_index]\n",
    "        \n",
    "        # add the score to scores\n",
    "        scores.append(score)\n",
    "        \n",
    "        # add the new feature to features\n",
    "        features.append(new_features[-1])\n",
    "        \n",
    "        \n",
    "        current_features = new_features\n",
    "        \n",
    "        # remove the now included feature from non-included features\n",
    "        non_included_features.remove(new_features[-1])\n",
    "        round_count += 1\n",
    "\n",
    "        # test for at least minimal improvement\n",
    "        if score - top_score > 0.0005:\n",
    "            no_improvement_count = 0\n",
    "            top_score = score\n",
    "            best_features = new_features\n",
    "\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "        \n",
    "    feature_scores = pd.DataFrame(list(zip(features, scores)),\n",
    "               columns =['Added feature', 'Score'])\n",
    "    \n",
    "    return feature_scores, best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afbf239",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9fb06",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Given that cp was the most important feature identified in the feature importances, let us take this as the first feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf553f13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:24:59.053188Z",
     "start_time": "2022-05-17T08:15:52.134131Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_feature_scores, rf_best_features = feature_evaluater(['cp']\n",
    "                                  , original_features + products + divisions\n",
    "                                  , RandomForestClassifier(random_state = 42, min_samples_leaf = 0.2)\n",
    "                                  , X_train\n",
    "                                  , y_train\n",
    "                                  , no_improvement_limit = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2bf3d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "That is the best performance that we have seen so far from a single algorithm.\n",
    "The previous best performance that we had seen from a RF was 0.858, so performance here has increased by over 1.5%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ff17b37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:27:40.975524Z",
     "start_time": "2022-05-17T08:27:40.951837Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Added feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oldpeak / age</td>\n",
       "      <td>0.821049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.844953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.856466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.865270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.873985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oldpeak / chol</td>\n",
       "      <td>0.872355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age * thalach</td>\n",
       "      <td>0.870178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.875368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trestbps * thalach</td>\n",
       "      <td>0.874736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.869393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>age</td>\n",
       "      <td>0.866643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Added feature     Score\n",
       "0        oldpeak / age  0.821049\n",
       "1                 thal  0.844953\n",
       "2                   ca  0.856466\n",
       "3                exang  0.865270\n",
       "4                slope  0.873985\n",
       "5       oldpeak / chol  0.872355\n",
       "6        age * thalach  0.870178\n",
       "7              thalach  0.875368\n",
       "8   trestbps * thalach  0.874736\n",
       "9              restecg  0.869393\n",
       "10                 age  0.866643"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14df84c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:27:57.856856Z",
     "start_time": "2022-05-17T08:27:57.841803Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp',\n",
       " 'oldpeak / age',\n",
       " 'thal',\n",
       " 'ca',\n",
       " 'exang',\n",
       " 'slope',\n",
       " 'oldpeak / chol',\n",
       " 'age * thalach',\n",
       " 'thalach']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f330e5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5a85f38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:35:08.576042Z",
     "start_time": "2022-05-17T08:33:23.534588Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_res_feature_scores, log_res_best_features = feature_evaluater([] ## do not give any features to begin with as we have nothing to work from \n",
    "                                              , original_features + products + divisions\n",
    "                                              , LogisticRegression(random_state = 42, C = 0.2)\n",
    "                                              , X_train\n",
    "                                              , y_train\n",
    "                                              , no_improvement_limit = 5) ##training is a lot quicker with LogRes so giving more scope for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf487ce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:35:12.817949Z",
     "start_time": "2022-05-17T08:35:12.789897Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Added feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.789757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thalach / chol</td>\n",
       "      <td>0.798406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldpeak * oldpeak</td>\n",
       "      <td>0.807593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.845465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chol * thalach</td>\n",
       "      <td>0.854392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oldpeak / thalach</td>\n",
       "      <td>0.863319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.863319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.862672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trestbps / chol</td>\n",
       "      <td>0.863698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chol * oldpeak</td>\n",
       "      <td>0.866865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trestbps * oldpeak</td>\n",
       "      <td>0.863961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chol * chol</td>\n",
       "      <td>0.863698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chol / trestbps</td>\n",
       "      <td>0.863698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chol / thalach</td>\n",
       "      <td>0.860965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>thalach * thalach</td>\n",
       "      <td>0.858701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Added feature     Score\n",
       "0                 thal  0.789757\n",
       "1       thalach / chol  0.798406\n",
       "2    oldpeak * oldpeak  0.807593\n",
       "3                   cp  0.845465\n",
       "4       chol * thalach  0.854392\n",
       "5    oldpeak / thalach  0.863319\n",
       "6                 chol  0.863319\n",
       "7              restecg  0.862672\n",
       "8      trestbps / chol  0.863698\n",
       "9       chol * oldpeak  0.866865\n",
       "10  trestbps * oldpeak  0.863961\n",
       "11         chol * chol  0.863698\n",
       "12     chol / trestbps  0.863698\n",
       "13      chol / thalach  0.860965\n",
       "14   thalach * thalach  0.858701"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_res_feature_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b4eab",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is also the best performance that we have seen from Logistic Regression, going from 0.862 to 0.867."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5354095f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b693b38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:39:46.513646Z",
     "start_time": "2022-05-17T08:38:08.295243Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svm_feature_scores, svm_best_features = feature_evaluater([] ## do not give any features to begin with as we have nothing to work from\n",
    "                                      , original_features + products + divisions\n",
    "                                      , SVC(random_state = 42, C = 1.0)\n",
    "                                      , X_train\n",
    "                                      , y_train\n",
    "                                      , no_improvement_limit = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b0bc661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:39:46.543916Z",
     "start_time": "2022-05-17T08:39:46.516506Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Added feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.796013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.810086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.832785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thalach / chol</td>\n",
       "      <td>0.847621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oldpeak / trestbps</td>\n",
       "      <td>0.850847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chol / thalach</td>\n",
       "      <td>0.850343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age * age</td>\n",
       "      <td>0.856790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chol * chol</td>\n",
       "      <td>0.857029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.856787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chol * thalach</td>\n",
       "      <td>0.866942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.870727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thalach * thalach</td>\n",
       "      <td>0.864464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>trestbps * chol</td>\n",
       "      <td>0.859486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>thalach / age</td>\n",
       "      <td>0.856673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Added feature     Score\n",
       "0                 thal  0.796013\n",
       "1                   ca  0.810086\n",
       "2                exang  0.832785\n",
       "3       thalach / chol  0.847621\n",
       "4   oldpeak / trestbps  0.850847\n",
       "5       chol / thalach  0.850343\n",
       "6            age * age  0.856790\n",
       "7          chol * chol  0.857029\n",
       "8                  sex  0.856787\n",
       "9       chol * thalach  0.866942\n",
       "10                chol  0.870727\n",
       "11   thalach * thalach  0.864464\n",
       "12     trestbps * chol  0.859486\n",
       "13       thalach / age  0.856673"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_feature_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f489c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Performance here far outstrips that seen with any other instance of SVC and in fact that top performing feature subset here outperforms that of LogisticRegression.\n",
    "Previously the top performance seen for SVC was 0.840."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395c6a0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa96ea3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With more time it would be a lot better to use different random seeds to generate a more varied set of results, from which we could draw a set of features that consistently occur in the optimal feature sets.\n",
    "Confidence in these results could also have been improved by varying the hyper-parameters to test a more varied set of circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0e63d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:42:57.519347Z",
     "start_time": "2022-05-17T08:42:57.509803Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cp', 'oldpeak / age', 'thal', 'ca', 'exang', 'slope', 'oldpeak / chol', 'age * thalach', 'thalach'] \n",
      "\n",
      "['thal', 'thalach / chol', 'oldpeak * oldpeak', 'cp', 'chol * thalach', 'oldpeak / thalach', 'chol', 'restecg', 'trestbps / chol', 'chol * oldpeak'] \n",
      "\n",
      "['thal', 'ca', 'exang', 'thalach / chol', 'oldpeak / trestbps', 'chol / thalach', 'age * age', 'chol * chol', 'sex', 'chol * thalach', 'chol'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rf_best_features, '\\n')\n",
    "print(log_res_best_features, '\\n')\n",
    "print(svm_best_features, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b5d11",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is interesting to see that despite being the most important feature for the random forest algorithm, cp does not even get used by the svm model.\n",
    "Secondly, the ratios and products are more prominent for the log_res and svm models than they are in rf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823ebc9",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1489d73b",
   "metadata": {},
   "source": [
    "Let's try to look to see how common the misclassifications are between the algorithms.\n",
    "If the overlap between errors is minimal then we can conclude that it might be possible to train an ensemble classifier to correctly classify these cases. However if all 3 algorithms are getting particular cases wrong then these issues would not be addressed by any ensemble of the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b5ef4",
   "metadata": {},
   "source": [
    "### rf and logres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e6da00b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T09:56:31.258099Z",
     "start_time": "2022-02-04T09:56:31.232221Z"
    }
   },
   "outputs": [],
   "source": [
    "def error_comparison(classifier_list, classifier_names_list, classifier_features_list, X_train, y_train):\n",
    "    \"\"\"\n",
    "    function to compare the errors of different classifiers on the same data set\n",
    "    \"\"\"\n",
    "    \n",
    "    # split the data into 5 folds\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    skf.get_n_splits(X_train, y_train)\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    # identify the overlap in errors for each split of the data\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        \n",
    "        # store the results for each individual data split\n",
    "        temp_results_df = pd.DataFrame()\n",
    "        \n",
    "        # identify the samples to be used in the split\n",
    "        X_train_k, X_test_k = X_train.iloc[train_index].copy(), X_train.iloc[test_index].copy()\n",
    "        y_train_k, y_test_k = y_train.iloc[train_index].copy(), y_train.iloc[test_index].copy()\n",
    "        \n",
    "        # add the correct classifications to the data frame\n",
    "        temp_results_df['y_test_k'] = y_test_k\n",
    "        \n",
    "        # find the predicted classes for each algorithm\n",
    "        for clf, clf_name, feature_list in list(zip(classifier_list, classifier_names_list, classifier_features_list)):\n",
    "             \n",
    "\n",
    "            # create the pipeline\n",
    "            pipeline = Pipeline([\n",
    "            ('selector', FeatureSelector(feature_list))\n",
    "            , ('preprocessor', preprocessor)\n",
    "            , (clf_name, clf)\n",
    "            ])\n",
    "            \n",
    "        \n",
    "            # fit pipeline\n",
    "            pipeline.fit(X_train_k[feature_list], y_train_k)\n",
    "            \n",
    "            # identify class predictions\n",
    "            predictions = pipeline.predict(X_test_k[feature_list])\n",
    "            \n",
    "            # add results to the data frame\n",
    "            temp_results_df[clf_name] = predictions\n",
    "            \n",
    "            # add prediction accuracy to dict\n",
    "            prior_results = result.get(clf_name, [])\n",
    "            prior_results.append((predictions == y_test_k).mean())\n",
    "            \n",
    "            result[clf_name] = prior_results\n",
    "        \n",
    "        # create a copy of the classifiers_name_list to remove each classifier once it has been used\n",
    "        names_copy = classifier_names_list.copy()\n",
    "        \n",
    "        for clf_name_1 in classifier_names_list:\n",
    "            names_copy.remove(clf_name_1)\n",
    "            \n",
    "            for clf_name_2 in names_copy:\n",
    "            \n",
    "                new_field_name = clf_name_1 + ' or ' + clf_name_2\n",
    "                \n",
    "                #get predictions for clfs\n",
    "                predictions_1 = temp_results_df[clf_name_1]\n",
    "                predictions_2 = temp_results_df[clf_name_2]\n",
    "                \n",
    "                #add prediction accuracy to dict\n",
    "                prior_results = result.get(new_field_name, [])\n",
    "                \n",
    "                prior_results.append(((predictions_2 == y_test_k) | (predictions_1 == y_test_k)).mean())\n",
    "            \n",
    "                result[new_field_name] = prior_results  \n",
    "                \n",
    "    final_results = pd.DataFrame(result)\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "6181e85c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T09:56:34.539661Z",
     "start_time": "2022-02-04T09:56:32.848154Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_list = [RandomForestClassifier(random_state = 42, min_samples_leaf = 0.2)\n",
    "                   , LogisticRegression(random_state = 42, C = 0.3)\n",
    "                  , SVC(random_state = 42, C = 1.0)]\n",
    "classifier_names_list = ['rf', 'log_res', 'svm']\n",
    "classifier_features_list = [rf_features, log_res_features, svm_features]\n",
    "\n",
    "resutls_df = error_comparison(classifier_list, classifier_names_list, classifier_features_list, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "549f3e93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T09:56:35.159882Z",
     "start_time": "2022-02-04T09:56:35.137788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>log_res</th>\n",
       "      <th>svm</th>\n",
       "      <th>rf or log_res</th>\n",
       "      <th>rf or svm</th>\n",
       "      <th>log_res or svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.895833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rf   log_res       svm  rf or log_res  rf or svm  log_res or svm\n",
       "0  0.816327  0.816327  0.795918       0.836735   0.877551        0.897959\n",
       "1  0.775510  0.795918  0.897959       0.836735   0.897959        0.897959\n",
       "2  0.875000  0.791667  0.833333       0.895833   0.916667        0.895833\n",
       "3  0.937500  0.916667  0.895833       0.958333   0.958333        0.916667\n",
       "4  0.833333  0.875000  0.854167       0.916667   0.895833        0.916667"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "28b97e0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T21:45:21.365349Z",
     "start_time": "2021-12-09T21:45:21.353131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "eed46499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T21:45:27.008005Z",
     "start_time": "2021-12-09T21:45:26.980666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>logres</th>\n",
       "      <th>either</th>\n",
       "      <th>improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rf    logres    either  improvement\n",
       "0  0.755102  0.734694  0.795918     0.040816\n",
       "1  0.795918  0.836735  0.836735     0.000000\n",
       "2  0.833333  0.854167  0.916667     0.062500\n",
       "3  0.854167  0.895833  0.895833     0.000000\n",
       "4  0.875000  0.895833  0.916667     0.020833"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_scores = pd.DataFrame(list(zip(correct_predictions_1, correct_predictions_2, either_correct)),columns =['rf', 'logres', 'either'])\n",
    "combined_scores['improvement'] = combined_scores['either'] - combined_scores[['rf', 'logres']].max(axis = 1)\n",
    "combined_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a221b",
   "metadata": {},
   "source": [
    "Ok so there is a minimal amount of improvement here. This suggests that a model that combined the predictions of both models in order to decide on which class to predict could improve by up to 4%. However there is no reason to believe that it would. In general the majority of cases that one algorithm gets wrong, the other algorithm also predicts incorrectly.\n",
    "Let us just see if this is any different when using a third algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eec632",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### rf and svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bc8afa75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T22:01:14.788657Z",
     "start_time": "2021-12-09T22:01:13.158696Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correct_predictions_1 = []\n",
    "correct_predictions_2 = []\n",
    "either_correct = []\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "        ('preprocessor', preprocessor)\n",
    "        , ('rf', RandomForestClassifier(class_weight = 'balanced', min_samples_leaf = 0.2))\n",
    "    ])\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "    , ('svm', SVC(class_weight = 'balanced', C = 0.3))\n",
    "    ])\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    \n",
    "    X_train_k, X_test_k = X_train.iloc[train_index].copy(), X_train.iloc[test_index].copy()\n",
    "    y_train_k, y_test_k = y_train.iloc[train_index].copy(), y_train.iloc[test_index].copy()\n",
    "    \n",
    "    # pipeline 1\n",
    "    pipeline1.fit(X_train_k[cont_features + disc_features], y_train_k)\n",
    "    \n",
    "    predictions_1 = pipeline1.predict(X_test_k[cont_features + disc_features])\n",
    "    \n",
    "    correct_predictions_1.append((predictions_1 == y_test_k).mean())\n",
    "    \n",
    "    # pipeline 2\n",
    "    pipeline2.fit(X_train_k[cont_features + disc_features], y_train_k)\n",
    "    \n",
    "    predictions_2 = pipeline2.predict(X_test_k[cont_features + disc_features])\n",
    "    \n",
    "    correct_predictions_2.append((predictions_2 == y_test_k).mean())\n",
    "    \n",
    "    \n",
    "    either_correct.append(((predictions_2 == y_test_k) | (predictions_1 == y_test_k)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "44fc7ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T22:01:17.693984Z",
     "start_time": "2021-12-09T22:01:17.669572Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>either</th>\n",
       "      <th>improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.061224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rf       svm    either  improvement\n",
       "0  0.755102  0.775510  0.795918     0.020408\n",
       "1  0.836735  0.816327  0.897959     0.061224\n",
       "2  0.875000  0.812500  0.916667     0.041667\n",
       "3  0.875000  0.833333  0.875000     0.000000\n",
       "4  0.895833  0.875000  0.937500     0.041667"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_scores = pd.DataFrame(list(zip(correct_predictions_1, correct_predictions_2, either_correct)),columns =['rf', 'svm', 'either'])\n",
    "combined_scores['improvement'] = combined_scores['either'] - combined_scores[['rf', 'svm']].max(axis = 1)\n",
    "combined_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ab734",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ok in cases where performance is poor there is some potential gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c44a25",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I don't understand why performance is generally performing as we go through the models. This seems unlikely to be a coincidence but I cannot identify what could be causing it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d15bc",
   "metadata": {},
   "source": [
    "### Trying with 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bf5a3777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T22:01:24.095476Z",
     "start_time": "2021-12-09T22:01:22.128301Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_predictions_1 = []\n",
    "correct_predictions_2 = []\n",
    "correct_predictions_3 = []\n",
    "best_of_3_correct = []\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "        ('preprocessor', preprocessor)\n",
    "        , ('rf', RandomForestClassifier(class_weight = 'balanced', min_samples_leaf = 0.2))\n",
    "    ])\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "    , ('svm', SVC(class_weight = 'balanced', C = 0.3))\n",
    "    ])\n",
    "\n",
    "pipeline3 = Pipeline([\n",
    "        ('preprocessor', preprocessor)\n",
    "        , ('logres', LogisticRegression(class_weight = 'balanced', C = 1.0))\n",
    "    ])\n",
    "\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    \n",
    "    X_train_k, X_test_k = X_train.iloc[train_index].copy(), X_train.iloc[test_index].copy()\n",
    "    y_train_k, y_test_k = y_train.iloc[train_index].copy(), y_train.iloc[test_index].copy()\n",
    "    \n",
    "    # pipeline 1\n",
    "    pipeline1.fit(X_train_k[cont_features + disc_features], y_train_k)\n",
    "    \n",
    "    predictions_1 = pipeline1.predict(X_test_k[cont_features + disc_features])\n",
    "    \n",
    "    correct_predictions_1.append((predictions_1 == y_test_k).mean())\n",
    "    \n",
    "    # pipeline 2\n",
    "    pipeline2.fit(X_train_k[cont_features + disc_features], y_train_k)\n",
    "    \n",
    "    predictions_2 = pipeline2.predict(X_test_k[cont_features + disc_features])\n",
    "    \n",
    "    correct_predictions_2.append((predictions_2 == y_test_k).mean())\n",
    "    \n",
    "    # pipeline 3\n",
    "    pipeline3.fit(X_train_k[cont_features + disc_features], y_train_k)\n",
    "    \n",
    "    predictions_3 = pipeline3.predict(X_test_k[cont_features + disc_features])\n",
    "    \n",
    "    correct_predictions_3.append((predictions_3 == y_test_k).mean())\n",
    "    \n",
    "    best_of_3 = ((predictions_2 == y_test_k) & (predictions_1 == y_test_k)) | ((predictions_3 == y_test_k) & (predictions_1 == y_test_k)) | ((predictions_3 == y_test_k) & (predictions_2 == y_test_k))\n",
    "    \n",
    "    best_of_3_correct.append(best_of_3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9c4f5241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T22:02:43.089817Z",
     "start_time": "2021-12-09T22:02:43.055136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>logres</th>\n",
       "      <th>best_of_3</th>\n",
       "      <th>improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>-0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rf       svm    logres  best_of_3  improvement\n",
       "0  0.714286  0.775510  0.734694   0.775510     0.000000\n",
       "1  0.795918  0.816327  0.836735   0.836735     0.000000\n",
       "2  0.875000  0.812500  0.854167   0.833333    -0.041667\n",
       "3  0.854167  0.833333  0.895833   0.854167    -0.041667\n",
       "4  0.875000  0.875000  0.895833   0.916667     0.020833"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_scores = pd.DataFrame(list(zip(correct_predictions_1, correct_predictions_2, correct_predictions_3, best_of_3_correct)),columns =['rf', 'svm', 'logres', 'best_of_3'])\n",
    "combined_scores['improvement'] = combined_scores['best_of_3'] - combined_scores[['rf', 'svm', 'logres']].max(axis = 1)\n",
    "combined_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceacd45",
   "metadata": {},
   "source": [
    "Ok so without any probabilistic elements this looks just as likely to have a negative impact as it is to have a positive impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45c585",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8a84e",
   "metadata": {},
   "source": [
    "In general the cases that are being predicted incorrectly are quite consistent across the algorithms that we have been trying. For this reason it is worth trying something like xgboost which specifically looks to bolster performance by targeting cases that are being predicted incorrectly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30191c8b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b188462d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T22:28:45.363376Z",
     "start_time": "2021-12-09T22:28:38.246127Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:28:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:28:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x000002024BF445B0>),\n",
       "                                                                        ('cat',\n",
       "                                                                         OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x000002024BF44FA0>)])),\n",
       "                                       ('classifier',\n",
       "                                        XGBC...\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      random_state=None,\n",
       "                                                      reg_alpha=None,\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      use_label_encoder=False,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             param_grid={'classifier__eta': [0.1, 0.3, 0.5],\n",
       "                         'classifier__max_depth': [3, 6, 9]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "    , ('classifier', XGBClassifier(use_label_encoder=False))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'classifier__max_depth' : [3, 6, 9]\n",
    "    , 'classifier__eta' : [0.1, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring= 'f1')\n",
    "\n",
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ea5960c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T22:28:49.067225Z",
     "start_time": "2021-12-09T22:28:49.043504Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.13787932, 0.15771422, 0.16086793, 0.12515678, 0.13286543,\n",
       "        0.13350229, 0.11890798, 0.12167983, 0.12245426]),\n",
       " 'std_fit_time': array([0.00401977, 0.00595612, 0.00100928, 0.00391245, 0.00259745,\n",
       "        0.00161635, 0.00549176, 0.00081128, 0.0018578 ]),\n",
       " 'mean_score_time': array([0.01497755, 0.01471515, 0.01553082, 0.01586776, 0.0154449 ,\n",
       "        0.01576281, 0.01517587, 0.01510777, 0.01536317]),\n",
       " 'std_score_time': array([0.0004538 , 0.00107665, 0.00063866, 0.00075124, 0.00056636,\n",
       "        0.00061837, 0.00120851, 0.00060906, 0.00081501]),\n",
       " 'param_classifier__eta': masked_array(data=[0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__max_depth': masked_array(data=[3, 6, 9, 3, 6, 9, 3, 6, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__eta': 0.1, 'classifier__max_depth': 3},\n",
       "  {'classifier__eta': 0.1, 'classifier__max_depth': 6},\n",
       "  {'classifier__eta': 0.1, 'classifier__max_depth': 9},\n",
       "  {'classifier__eta': 0.3, 'classifier__max_depth': 3},\n",
       "  {'classifier__eta': 0.3, 'classifier__max_depth': 6},\n",
       "  {'classifier__eta': 0.3, 'classifier__max_depth': 9},\n",
       "  {'classifier__eta': 0.5, 'classifier__max_depth': 3},\n",
       "  {'classifier__eta': 0.5, 'classifier__max_depth': 6},\n",
       "  {'classifier__eta': 0.5, 'classifier__max_depth': 9}],\n",
       " 'split0_test_score': array([0.8       , 0.76363636, 0.76363636, 0.7037037 , 0.71698113,\n",
       "        0.71698113, 0.74074074, 0.75      , 0.75      ]),\n",
       " 'split1_test_score': array([0.85245902, 0.83870968, 0.83870968, 0.85245902, 0.8       ,\n",
       "        0.8       , 0.83870968, 0.83870968, 0.83870968]),\n",
       " 'split2_test_score': array([0.83018868, 0.82352941, 0.83018868, 0.84615385, 0.84615385,\n",
       "        0.86792453, 0.76      , 0.81632653, 0.81632653]),\n",
       " 'split3_test_score': array([0.94117647, 0.88461538, 0.92307692, 0.90196078, 0.90196078,\n",
       "        0.92      , 0.90196078, 0.85714286, 0.88      ]),\n",
       " 'split4_test_score': array([0.84615385, 0.85714286, 0.84      , 0.8627451 , 0.84615385,\n",
       "        0.84615385, 0.84      , 0.82352941, 0.82352941]),\n",
       " 'mean_test_score': array([0.8539956 , 0.83352674, 0.83912233, 0.83340449, 0.82224992,\n",
       "        0.8302119 , 0.81628224, 0.8171417 , 0.82171312]),\n",
       " 'std_test_score': array([0.04721579, 0.04044563, 0.05065028, 0.06768863, 0.06176276,\n",
       "        0.06851607, 0.05878868, 0.03637237, 0.04209829]),\n",
       " 'rank_test_score': array([1, 3, 2, 4, 6, 5, 9, 8, 7])}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd7f56",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This has not initially proved any more useful than other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb0f365",
   "metadata": {},
   "source": [
    "## Unused material that may prove useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f7a21fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T09:15:45.760447Z",
     "start_time": "2022-01-26T09:15:45.742977Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up a train, validation set for use\n",
    "X_train_2, X_val, y_train_2, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a2d6b",
   "metadata": {},
   "source": [
    "## Messing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "70d754d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:08:51.850316Z",
     "start_time": "2022-02-02T09:08:51.821018Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_subset = original_features + products + divisions\n",
    "feature_subset.remove('thal')\n",
    "feature_subset.remove('cp')\n",
    "\n",
    "set_features = ['thal', 'cp']\n",
    "round_count = 1\n",
    "\n",
    "top_score = 0.8\n",
    "\n",
    "while True:\n",
    "    new_feature_subsets = tuple([set_features + [feature] for feature in feature_subset])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('selector', FeatureSelector())\n",
    "    , ('preprocessor', preprocessor)\n",
    "    , ('clf', ClfSwitcher())\n",
    "    ])\n",
    "\n",
    "    parameters = [{\n",
    "            'clf__estimator' : [RandomForestClassifier(random_state = 42, min_samples_leaf = 0.2)]\n",
    "            , 'selector__chosen_features' : new_feature_subsets\n",
    "        }\n",
    "\n",
    "        ,{\n",
    "           'clf__estimator' : [LogisticRegression(random_state = 42, C = 0.3)]\n",
    "            , 'selector__chosen_features' : new_feature_subsets\n",
    "        }\n",
    "\n",
    "        ,{\n",
    "           'clf__estimator' : [SVC(random_state = 42, C = 1.0)]\n",
    "            , 'selector__chosen_features' : new_feature_subsets\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    gscv_99 = GridSearchCV(pipeline, parameters, cv = 5, scoring = 'f1')\n",
    "    gscv_99.fit(X_train, y_train)\n",
    "    \n",
    "    gs99_results = pd.DataFrame(gscv_99.cv_results_)\n",
    "    \n",
    "    gs99_results['features'] = gs99_results['param_selector__chosen_features'].apply(lambda x: tuple(x))\n",
    "    \n",
    "    scores = gs99_results.groupby('features')['mean_test_score'].mean()\n",
    "    new_features = scores.idxmax()\n",
    "    score = scores[new_features]\n",
    "    print(round_count, new_features, score)\n",
    "    \n",
    "    percent_increase = (score - top_score) / top_score\n",
    "    \n",
    "    if percent_increase > 0.001:\n",
    "        top_score = score\n",
    "        set_features = list(new_features)\n",
    "        feature_subset.remove(new_features[-1])\n",
    "        round_count += 1\n",
    "    \n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
